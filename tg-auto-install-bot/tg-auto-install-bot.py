import requests
import os
import shlex
from tqdm import tqdm
import subprocess
import logging
import re
import time
import string
import threading
import concurrent.futures

# å…¨å±€å˜é‡
bot_token = ""  # æ›¿æ¢ä¸ºæ‚¨çš„Telegram Botçš„ä»¤ç‰Œ
download_path = "/home/tgmedia"  # ä¸‹è½½æ–‡ä»¶çš„æœ¬åœ°ä¿å­˜è·¯å¾„ï¼Œè‹¥å¼€å¯rcloneä¸Šä¼ ï¼Œå³æ–‡ä»¶ä¸­è½¬åœ°å€
enable_upload = True  # æ˜¯å¦å¼€å¯rcloneä¸Šä¼ ï¼Œæ ¹æ®éœ€è¦è®¾ç½®ä¸ºTrueæˆ–Falseï¼Œrcloneä¸Šä¼ é»˜è®¤ä¸º"move"ï¼Œå³rcloneä¸Šä¼ åä¼šåˆ é™¤æœ¬åœ°æ–‡ä»¶
remote_path = "ç›˜ç¬¦:è·¯å¾„"  # rcloneä¸Šä¼ æ–‡ä»¶çš„è¿œç¨‹è·¯å¾„
api_base_url = "http://127.0.0.1:8081/bot" # å®é™…çš„Telegram Bot Apiè¯·æ±‚åœ°å€
logging_file = "/tmp/tg-auto-install-bot.log" # æ—¥å¿—è®°å½•æ–‡ä»¶
allowed_user_ids = [aaa,bbb,-ccc]  # å…è®¸çš„ç”¨æˆ·æˆ–è€…ç¾¤ç»„IDåˆ—è¡¨ï¼Œå¤šä¸ªç”¨è‹±æ–‡é€—å·éš”å¼€
cleanup_interval = 3600  # å®šä¹‰æ¸…ç†æ—§æ•°æ®çš„æ—¶é—´é—´éš”ï¼ˆä»¥ç§’ä¸ºå•ä½ï¼‰
remote_url = "https://xxx.com/odrive" ## alistç­‰åˆ—è¡¨ç¨‹åºï¼Œè¿œç¨‹äº‘ç›˜å¯¹åº”remote_pathçš„ç›®å½•

media_group_id_start_count = {}
media_group_id_end_count = {}

# åˆ›å»ºçº¿ç¨‹æ± 
pool = concurrent.futures.ThreadPoolExecutor(max_workers=3) # å¤„ç†tgæ–‡ä»¶æ—¶çš„å¹¶å‘çº¿ç¨‹æ•°ï¼Œé»˜è®¤ä¸º3

# é…ç½®æ—¥å¿—è¾“å‡º
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s',filename=logging_file)
logger = logging.getLogger(__name__)

def create_directory(directory):
    if not os.path.exists(directory):
        os.makedirs(directory)
        logger.info(f"å·²åˆ›å»ºç›®å½•ï¼š{directory}")

def format_size(size):
    # æ ¼å¼åŒ–æ–‡ä»¶å¤§å°æ˜¾ç¤º
    size = float(size)
    if size < 1024:
        return f"{size:.2f} B"
    elif size < 1024 ** 2:
        return f"{size / 1024:.2f} KB"
    elif size < 1024 ** 3:
        return f"{size / (1024 ** 2):.2f} MB"
    else:
        return f"{size / (1024 ** 3):.2f} GB"

def send_reply(chat_id, message_id, text, time_sleep, link_url):
    url = f"{api_base_url}{bot_token}/sendMessage"
    params = {
        "chat_id": chat_id,
        "reply_to_message_id": message_id,
        "text": text,
        "parse_mode": "HTML",
        "disable_web_page_preview": "true"
    }
    response = requests.get(url, params=params)
    reply_message_id = None
    if response.status_code == 200:
        data = response.json()
        reply_message_id = data["result"]["message_id"]  # æå–å›å¤æ¶ˆæ¯çš„ message_id
        logger.info(f"tgå›å¤æ¶ˆæ¯id {message_id} æˆåŠŸï¼")
    else:
        logger.info(f"tgå›å¤æ¶ˆæ¯id {message_id} å¤±è´¥ï¼")
    
    #åˆ é™¤å›å¤çš„æ¶ˆæ¯
    thread = threading.Thread(target=delete_latest_message, args=(chat_id, reply_message_id, time_sleep))
    thread.start()
   
def delete_latest_message(chat_id, message_id, time_sleep):
    time.sleep(time_sleep)
    url = f"{api_base_url}{bot_token}/deleteMessage"
    params = {
        "chat_id": chat_id,
        "message_id": message_id
    }
    response = requests.get(url, params=params)
    if response.status_code == 200:
        logger.info("æˆåŠŸåˆ é™¤æ¶ˆæ¯{message_id}ï¼")
    else:
        logger.info("åˆ é™¤æœ€æ–°çš„æ¶ˆæ¯{message_id}ï¼")

def generate_filename(file_name, file_size, caption, file_getpath):
    # ç”Ÿæˆæ–°çš„æ–‡ä»¶å
    file_extension = os.path.splitext(file_name)[1] or os.path.splitext(file_getpath)[1]
    file_size_str = f"({format_size(file_size)})"
    new_file_name = file_name

    if all(char in string.ascii_letters + string.digits + string.punctuation for char in file_name):
        if caption:
            new_file_name = caption[:40]
        else:
            new_file_name = os.path.splitext(file_name)[0]  # å»é™¤åŸå§‹æ–‡ä»¶åçš„åç¼€

    else:
        new_file_name = os.path.splitext(file_name)[0]  # å»é™¤åŸå§‹æ–‡ä»¶åçš„åç¼€


    new_file_name = f"{new_file_name}{file_size_str}{file_extension}"
    return new_file_name    

def download_file(url, file_type, file_name, caption, file_getpath, message_id, chat_id, media_group_id, file_size):
       
    total_size = file_size

    file_name_with_size = generate_filename(file_name, total_size, caption, file_getpath)
    logger.info(f"æ–‡ä»¶é‡å‘½åä¸ºï¼š{file_name_with_size}")

    if media_group_id:
        if caption:
            caption_path = caption[:40]
            file_type = f"media_group/{caption_path}ã€{media_group_id}ã€‘"
        else:
            file_type = f"media_group/ã€{media_group_id}ã€‘"

    sub_directory = os.path.join(download_path, file_type)
    create_directory(sub_directory)

    file_path = os.path.join(sub_directory, file_name_with_size)

    os.link(file_getpath, file_path) 
    logger.info(f"{file_getpath},{file_path}")
    
    if enable_upload:
        # æ„é€ è¿œç¨‹è·¯å¾„
        remote_file_path = f"{remote_path}/{file_type}"
            
        # è°ƒç”¨rcloneå‘½ä»¤ä¸Šä¼ æ–‡ä»¶
        # å¼•ç”¨è·¯å¾„ä»¥å¤„ç†ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦
        quoted_file_path = shlex.quote(file_path)
        quoted_remote_file_path = shlex.quote(remote_file_path)

        logger.info(f"rcloneæœ¬åœ°åœ°å€:{quoted_file_path}")
        logger.info(f"rcloneè¿œç¨‹åœ°å€:{quoted_remote_file_path}")
            
        rclone_command = f"rclone move {quoted_file_path} {quoted_remote_file_path} -P"
        result = subprocess.run(rclone_command, shell=True)
        
        time_sleep = 600
        link_url = remote_url + "/" + file_type + "/" + file_name_with_size
        if media_group_id:
            link_url = remote_url + "/" + file_type
            if media_group_id in media_group_id_end_count:
                media_group_id_end_count[media_group_id] += 1
            else:
                media_group_id_end_count[media_group_id] = 1

            media_group_id_start_time = media_group_id_start_count[media_group_id] #æ€»å…±æ¬¡æ•°
            media_group_id_end_time = media_group_id_end_count[media_group_id] #å·²ç»å‡ºç°æ¬¡æ•°
            logging.info("æ€»å…± {media_group_id_start_time} å·²ç»{media_group_id_end_time}")
            
            if media_group_id_start_time == media_group_id_end_time:
                logging.info(f"{media_group_id_end_time}ä¸ªæ–‡ä»¶å…¨éƒ¨ä¸Šä¼ å®Œæˆ")
                reply_text = f"{media_group_id_end_time}ä¸ªæ–‡ä»¶å…¨éƒ¨ä¸Šä¼ å®Œæˆ\n\n<a href='{link_url}'>æ–‡ä»¶é“¾æ¥</a>"
                send_reply(chat_id, message_id, reply_text, time_sleep, link_url)   
        else:
            if result.returncode == 0:
                logging.info("æ–‡ä»¶ {file_name_with_size} ä¸Šä¼ å®Œæˆ")
                reply_text = f"æ–‡ä»¶ {file_name_with_size} ä¸Šä¼ å®Œæˆ\n\n<a href='{link_url}'>æ–‡ä»¶é“¾æ¥</a>"
                send_reply(chat_id, message_id, reply_text, time_sleep, link_url)
            else:
                logging.error(f"æ–‡ä»¶ {file_name_with_size} ä¸Šä¼ å¤±è´¥ï¼Œè¿”å›ç ï¼š{result.returncode}")
                reply_text = f"æ–‡ä»¶ {file_name_with_size} ä¸Šä¼ å¤±è´¥ï¼Œè¿”å›ç ï¼š{result.returncode}"
                send_reply(chat_id, message_id, reply_text, time_sleep, link_url)
             
def download_media_file(file_id, file_name, file_type, caption, message_id, chat_id, media_group_id):
    #print(threading.current_thread().getName(), 'Starting')
    get_file_url = f"{api_base_url}{bot_token}/getFile"
    params = {"file_id": file_id}

    response = requests.get(get_file_url, params=params)
    file_info = response.json()
    logger.info(f" {file_id} æ–‡ä»¶è·å–file_pathï¼š{file_info} ")

    if file_info["ok"]:
        file_path = file_info["result"]["file_path"]
        file_size = file_info["result"]["file_size"]
        file_url = f"{api_base_url}{bot_token}/{file_path}"
        download_file(file_url, file_type, file_name, caption, file_path, message_id, chat_id, media_group_id, file_size)
    else:
        logger.error("è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥ã€‚")

def process_message(message, media_group_captions, caption, media_group_id):
    message_id = message['message_id']
    chat_id = message['chat']['id']

    # å°†captionä¼ é€’ç»™åŒä¸€media_group_idçš„å…¶ä»–æ–‡ä»¶
    if media_group_id and media_group_id in media_group_captions:
        caption = media_group_captions[media_group_id]
    
    # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦åœ¨å…è®¸çš„ç”¨æˆ·IDåˆ—è¡¨ä¸­
    if chat_id not in allowed_user_ids:
        logger.info(f"æœªç»æˆæƒçš„ç”¨æˆ·ï¼š{chat_id}")
        return

    if "photo" in message:
        # å¤„ç†ç…§ç‰‡
        photo = message["photo"][-1]  # è·å–æœ€åä¸€å¼ ç…§ç‰‡ï¼ˆåŸå§‹åˆ†è¾¨ç‡ï¼‰
        file_id = photo["file_id"]
        file_name = photo.get("file_name", "photo")
        logger.info(f"æ”¶åˆ°ç…§ç‰‡æ¶ˆæ¯ï¼Œå¼€å§‹ä¸‹è½½ï¼š{file_name}")
        # download_media_file(file_id, file_name, "photos",caption, message_id, chat_id, media_group_id)
        pool.submit(download_media_file, file_id, file_name, "photos", caption, message_id, chat_id, media_group_id)

    if "document" in message:
        # å¤„ç†æ–‡æ¡£
        document = message["document"]
        file_id = document["file_id"]
        file_name = document.get("file_name", "document")
        logger.info(f"æ”¶åˆ°æ–‡æ¡£æ¶ˆæ¯ï¼Œå¼€å§‹ä¸‹è½½ï¼š{file_name}")
        # download_media_file(file_id, file_name, "documents",caption, message_id, chat_id, media_group_id)
        pool.submit(download_media_file, file_id, file_name, "documents", caption, message_id, chat_id, media_group_id)

    if "video" in message:
        # å¤„ç†è§†é¢‘
        video = message["video"]
        file_id = video["file_id"]
        file_name = video.get("file_name", "video")
        logger.info(f"æ”¶åˆ°è§†é¢‘æ¶ˆæ¯ï¼Œå¼€å§‹ä¸‹è½½ï¼š{file_name}")
        #download_media_file(file_id, file_name, "videos",caption, message_id, chat_id, media_group_id)
        #thread = threading.Thread(target=download_media_file, args=(file_id, file_name, "videos", caption, message_id, chat_id, media_group_id))
        #thread.start()
        
        # æäº¤ä»»åŠ¡ç»™çº¿ç¨‹æ± åå°æ‰§è¡Œ
        pool.submit(download_media_file, file_id, file_name, "videos", caption, message_id, chat_id, media_group_id) 

    if "audio" in message:
        # å¤„ç†éŸ³é¢‘
        audio = message["audio"]
        file_id = audio["file_id"]
        file_name = audio.get("file_name", "audio")
        logger.info(f"æ”¶åˆ°éŸ³é¢‘æ¶ˆæ¯ï¼Œå¼€å§‹ä¸‹è½½ï¼š{file_name}")
        # download_media_file(file_id, file_name, "audios",caption, message_id, chat_id, media_group_id)
        pool.submit(download_media_file, file_id, file_name, "audios", caption, message_id, chat_id, media_group_id)

    if "text" in message:
        # å¤„ç†æ–‡æœ¬æ–‡ä»¶
        text = message["text"]
        #if (text.startswith("/ping") or text.startswith("/start")) and len(text) == 5:
        if (text.startswith("/ping") and len(text) == 5) or (text.startswith("/start") and len(text) == 6):
        #if text.startswith("/ping") and len(text) == 5:
            # å¦‚æœæ¶ˆæ¯ä»¥ /ping å¼€å¤´ï¼Œå›å¤ Pong! ğŸ“
            link_url = None
            time_sleep = 2
            send_reply(chat_id, message_id, "Pong! ğŸ“", time_sleep, link_url)

            #åˆ é™¤å›å¤çš„æ¶ˆæ¯
            thread = threading.Thread(target=delete_latest_message, args=(chat_id, message_id, time_sleep))
            thread.start()
            
        if text.startswith("http") or text.startswith("www"):
            logger.info("æ”¶åˆ°æ–‡æœ¬æ¶ˆæ¯ï¼Œå¼€å§‹ä¸‹è½½...")
            # å¯ä»¥ä½¿ç”¨requestsåº“ä¸‹è½½æ–‡æœ¬æ–‡ä»¶
            # ä¸‹è½½é€»è¾‘...

def get_updates(offset=None):
    get_updates_url = f"{api_base_url}{bot_token}/getUpdates"
    params = {"offset": offset}

    response = requests.get(get_updates_url, params=params)
    updates = response.json()

    if updates["ok"]:
        return updates["result"]
    else:
        return []

def cleanup_media_group_captions(media_group_captions, media_group_timestamps):
    current_time = time.time()
    # éå†å­—å…¸ä¸­çš„æ‰€æœ‰é¡¹
    for media_group_id, timestamp in list(media_group_timestamps.items()):
        # æ£€æŸ¥æ—¶é—´æˆ³æ˜¯å¦è¶…è¿‡æ¸…ç†é—´éš”
        if current_time - timestamp > cleanup_interval:
            # åˆ é™¤æ—§æ•°æ®
            del media_group_captions[media_group_id]
            del media_group_timestamps[media_group_id]

def get_captions(media_group_id, last_update_id1, media_group_captions, media_group_timestamps):   
    new_updates = get_updates(offset=last_update_id1)
    if new_updates:
        logger.info(f"è°ƒç”¨è¯·æ±‚captionå‡½æ•°ï¼Œlast_update_id1ï¼š[{last_update_id1}]")
        logger.info(f"è°ƒç”¨è¯·æ±‚captionå‡½æ•°ï¼Œupdatesï¼š[{new_updates}]")
        for update in new_updates:
            if "message" in update:
                new_message = update["message"]
                new_media_group_id = new_message.get("media_group_id")
                caption = new_message.get("caption")
                logger.info(f"è°ƒç”¨å‡½æ•°,{last_update_id1} ï¼Œæ–°new_message{new_message}ï¼Œæ–°new_media_group_id{new_media_group_id}ï¼Œæ–°captain{caption}")
                
                if new_media_group_id == media_group_id:
                    if caption:
                        caption = re.sub(r'\n+', ' ', caption) #å¤„ç†é¿å…æ¢è¡Œç¬¦
                        logger.info(f"è°ƒç”¨å‡½æ•°,media_group_id {media_group_id} å­˜åœ¨caption {caption}") 
                        get_media_group_captions(caption, media_group_id, media_group_captions, media_group_timestamps)  
                        return caption
                    else:
                        logger.info(f"è°ƒç”¨å‡½æ•°ï¼Œæœªè·å–åˆ°captain ï¼Œlast_update_id {last_update_id1} ç»§ç»­è·å–caption")
                else:
                    logger.info(f"é€€å‡ºè°ƒç”¨å‡½æ•°ï¼Œåç»­ä¸ºmedia_group_idä¸åŒéƒ¨åˆ†ï¼ŒåŸæ¥{media_group_id} ã€æ–°çš„{new_media_group_id}ï¼ï¼ï¼") 
                    return 

def get_media_group_captions(caption, media_group_id, media_group_captions, media_group_timestamps):
    if caption and media_group_id:
        if media_group_id not in media_group_captions:
            media_group_captions[media_group_id] = caption  # å­˜å‚¨ caption
            media_group_timestamps[media_group_id] = time.time()  # å­˜å‚¨æ—¶é—´æˆ³
            logger.info(f"å­˜å‚¨æœ‰æ•ˆcaptain media_group_idå­—å…¸å¯¹ã€‚captainï¼š[{caption}]ï¼›media_group_idï¼š[{media_group_id}]")
        else:
            # æ›´æ–°æ—¶é—´æˆ³
            media_group_timestamps[media_group_id] = time.time()

        # æ¸…ç†æ—§æ•°æ®
        cleanup_media_group_captions(media_group_captions, media_group_timestamps) 
                             
def main():
    last_update_id = None
    media_group_captions = {}  # media_group_captions å­—å…¸åˆå§‹åŒ–ä¸ºç©º
    
    # å®šä¹‰å­˜å‚¨æ—¶é—´æˆ³çš„å­—å…¸
    media_group_timestamps = {}
    

    while True:
        updates = get_updates(offset=last_update_id)

        if updates:
            #logger.info(f"if updates: {updates}")
            #ä»å•æ¬¡æ›´æ–°çš„æ‰€æœ‰æ¶ˆæ¯ä¸­è·å–caption
            logger.info(f"ä»è·å–çš„æ‰€æœ‰æ¶ˆæ¯ä¸­è·å–caption")
            for update in updates:
                if "message" in update:
                    message = update["message"]
                    caption = message.get("caption")
                    media_group_id = message.get("media_group_id")

                    if caption:
                        caption = re.sub(r'\n+', ' ', caption) #å¤„ç†é¿å…æ¢è¡Œç¬¦

                    get_media_group_captions(caption, media_group_id, media_group_captions, media_group_timestamps)
            logger.info(f"å¼€å§‹forå¾ªç¯ï¼Œé€ä¸€å¤„ç†è·å–çš„æ‰€æœ‰æ¶ˆæ¯...")
            for update in updates:
                #logger.info(f"for update in updatesï¼š{update}")
                if "message" in update:
                    message = update["message"]
                    logger.info(f"å¾ªç¯ä¸­ï¼Œå½“å‰å¤„ç†çš„æ¶ˆæ¯ï¼Œupdate_id:[{last_update_id}]ï¼Œmessage:[{message}]")
                    
                    media_group_id = message.get("media_group_id")
                    caption = message.get("caption")
                    if caption:
                        caption = re.sub(r'\n+', ' ', caption) #å¤„ç†é¿å…æ¢è¡Œç¬¦
                    if media_group_id:
                        if media_group_id in media_group_id_start_count:
                            media_group_id_start_count[media_group_id] += 1
                        else:
                            media_group_id_start_count[media_group_id] = 1

                    # è‹¥media_group_idä¸ä¸ºç©ºï¼Œä»å­—å…¸æŸ¥çœ‹æ˜¯å¦æœ‰caption
                    if media_group_id and media_group_id in media_group_captions:
                        caption = media_group_captions[media_group_id]

                    # ä»å­—å…¸æŸ¥çœ‹æ²¡æœ‰captionï¼Œåˆå­˜åœ¨media_group_idï¼Œé‡æ–°è¯·æ±‚ä¸‹ä¸€è½®tgæ¶ˆæ¯ï¼Œè·å–caption
                    if media_group_id and not caption:
                        last_update_id1 = update["update_id"] + 1
                        #ç”¨ä¸‹ä¸€ä¸ªlast_update_idï¼Œé‡æ–°è¯·æ±‚tgæ¶ˆæ¯
                        caption = get_captions(media_group_id, last_update_id1, media_group_captions, media_group_timestamps)
                        if caption:
                            caption = re.sub(r'\n+', ' ', caption) #å¤„ç†é¿å…æ¢è¡Œç¬¦
                            logger.info(f"è¯·æ±‚ä¸‹ä¸€ä¸ªupdate_id {last_update_id1}ä»¥åçš„æ‰€æœ‰æ¶ˆæ¯ï¼Œå‘ç°media_group_id [{media_group_id}] å­˜åœ¨caption [{caption}]") 
                        else:
                            logger.info(f"è¯·æ±‚ä¸‹ä¸€ä¸ªupdate_id {last_update_id1}ä»¥åçš„æ‰€æœ‰æ¶ˆæ¯ï¼Œå‘ç°media_group_id [{media_group_id}] ä¸å­˜åœ¨caption ï¼ï¼ï¼")                
                    
                    process_message(message, media_group_captions, caption, media_group_id)
                     
                last_update_id = update["update_id"] + 1

if __name__ == "__main__":
    create_directory(download_path)
    main()

