import requests
import os
import shlex
import subprocess
import logging
import re
import time
import string
import threading
import concurrent.futures

## å…¨å±€å˜é‡

## Telegram Botçš„ä»¤ç‰Œtoken
bot_token = "1111:aaaa"  

## æ–‡ä»¶çš„æœ¬åœ°ä¿å­˜åœ°å€ï¼Œä½¿ç”¨çš„æ˜¯ç¡¬é“¾æ¥æ–‡ä»¶ï¼›è‹¥å¼€å¯rcloneä¸Šä¼ ï¼Œåˆ™ä¸ºrcloneä¸Šä¼ æ—¶çš„æ–‡ä»¶ä¸­è½¬åœ°å€
## æ³¨æ„é¡»ä¸telegram-bot-apiçš„æ–‡ä»¶ä¸‹è½½ä½ç½®ã€é»˜è®¤/var/lib/telegram-bot-apiã€‘ä½äºåŒä¸€ç¡¬ç›˜ï¼Œä¸ç„¶ç¡¬é“¾æ¥ä¼šå¤±è´¥
## å¦‚å­˜åœ¨æ–‡ä»¶è·¨ç›˜ç§»åŠ¨ï¼Œåˆ™éœ€è¦é€šè¿‡å¼€å¯rcloneä¸Šä¼ å®ç°
## download_path ç›®å½•æ— éœ€æå‰åˆ›å»ºï¼Œç¨‹åºè¿è¡Œåä¼šè‡ªåŠ¨åˆ›å»º
download_path = "/media/tgmedia/"  

## æ˜¯å¦å¼€å¯crloneä¸Šä¼ ï¼ŒTrue/Falseï¼›å¦‚ä¸å¼€å¯ä¸Šä¼ ï¼Œä¸éœ€è¦å®‰è£…rcloneï¼Œæ–‡ä»¶ä¿å­˜åœ¨ download_path
enable_upload = True 

## rcloneä¸Šä¼ æ–‡ä»¶çš„è¿œç¨‹è·¯å¾„ï¼Œé»˜è®¤ä¸ºrclone moveï¼Œä¸Šä¼ å®Œæˆä¼šåˆ é™¤ download_path ç›®å½•ä¸‹çš„æœ¬åœ°æ–‡ä»¶; e.g. /media/tgè½¬å­˜  onedrive:/
remote_path = ""

## ä¸éœ€è¦ä¿®æ”¹,å®é™…çš„Telegram Bot Apiè¯·æ±‚åœ°å€ï¼Œåªèƒ½ä½¿ç”¨è‡ªå»ºapi
api_base_url = "http://127.0.0.1:8081/bot" 

## ä¸éœ€è¦ä¿®æ”¹,æ—¥å¿—è®°å½•æ–‡ä»¶ï¼Œå®æ—¶æŸ¥çœ‹æ—¥å¿—æœ€å200è¡Œï¼Œtail -f -n 200 /tmp/tg-auto-install-bot.log
logging_file = "/tmp/tg-auto-install-bot.log" 

## å…è®¸çš„ç”¨æˆ·æˆ–è€…ç¾¤ç»„IDåˆ—è¡¨ï¼Œå¤šä¸ªç”¨è‹±æ–‡é€—å·éš”å¼€
allowed_user_ids = [aaaa, bbbb,-cccc,-dddd]  

## ä¸éœ€è¦ä¿®æ”¹ï¼Œå®šä¹‰æ¸…ç†æ—§æ•°æ®çš„æ—¶é—´é—´éš”ï¼ˆä»¥ç§’ä¸ºå•ä½ï¼‰
cleanup_interval = 3600  

## alistç­‰åˆ—è¡¨ç¨‹åºï¼Œè¿œç¨‹äº‘ç›˜å¯¹åº”remote_pathçš„ç›®å½•ï¼Œå›å¤æ¶ˆæ¯æ—¶ç”¨çš„linkæ‹¼æ¥
remote_url = "http://url" 

## telegram-bot-apiè¿œç«¯è¯·æ±‚å¯é‡å¤æ¬¡æ•°ï¼Œæ¯ä¸€æ¬¡ä¸º30sï¼Œè¶…è¿‡æ¬¡æ•°åˆ™è¯¥æ–‡ä»¶ä¸‹è½½å¤±è´¥
max_retries=200

## è¯·æ±‚telegram-bot-apiçš„é—´éš”æ—¶é—´ï¼Œæ­é…max_retriesä½¿ç”¨ã€‚å¦‚ç½‘é€Ÿå¾ˆæ…¢ï¼Œè°ƒé«˜max_retrieså³å¯
retry_delay=5

## è°ƒç”¨yt-dlpä¸‹è½½è§†é¢‘ï¼Œé»˜è®¤å…³é—­ï¼ŒTrue/Falseï¼›å¦‚å¯ç”¨è¯·å®‰è£…å¯¼å…¥yt-dlpä»¥åŠå®‰è£…ffmpeg
## yt-dlpä¸€é”®å®‰è£…è„šæœ¬ï¼Œbash <(curl -L -s https://raw.githubusercontent.com/ershiyi21/myprogram/main/yt/yt_install.sh)
## è§†é¢‘é€‰é›†é“¾æ¥å¿…é¡»æŒ‡å®špï¼Œåœ¨æœ«å°¾æ·»åŠ  &p=1ï¼Œä¸ç„¶ä¼šå‡ºé”™ï¼›å°¤å…¶æ˜¯bç«™
ytdlp = False

## åˆ é™¤ä¿¡æ¯çš„é»˜è®¤æ—¶é—´ï¼Œæ— éœ€ä¿®æ”¹
time_sleep = 600
link_url = None

media_group_id_start_count = {}
media_group_id_end_count = {}

# åˆ›å»ºçº¿ç¨‹æ± 
pool = concurrent.futures.ThreadPoolExecutor(max_workers=3) # å¤„ç†tgæ–‡ä»¶æ—¶çš„å¹¶å‘çº¿ç¨‹æ•°ï¼Œé»˜è®¤ä¸º3

# é…ç½®æ—¥å¿—è¾“å‡º
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s',filename=logging_file)
logger = logging.getLogger(__name__)

def create_directory(directory):
    if not os.path.exists(directory):
        os.makedirs(directory)
        logger.info(f"å·²åˆ›å»ºç›®å½•ï¼š{directory}")

def create_empty_file(file_path):
    # è‡ªåŠ¨åˆ›å»ºç›®å½•
    directory = os.path.dirname(file_path)
    if directory and not os.path.exists(directory):
        os.makedirs(directory)

    # åˆ›å»ºç©ºæ–‡ä»¶ï¼ˆä¸è¦†ç›–å·²æœ‰å†…å®¹ï¼‰
    if not os.path.exists(file_path):
        with open(file_path, "w", encoding="utf-8"):
            pass
        logger.info(f"å·²åˆ›å»ºç©ºç™½æ–‡ä»¶ï¼š{file_path}")
        return True
    else:
        logger.info(f"æ–‡ä»¶å·²å­˜åœ¨ï¼š{file_path}")
        return False

def format_size(size):
    # æ ¼å¼åŒ–æ–‡ä»¶å¤§å°æ˜¾ç¤º
    size = float(size)
    if size < 1024:
        return f"{size:.2f} B"
    elif size < 1024 ** 2:
        return f"{size / 1024:.2f} KB"
    elif size < 1024 ** 3:
        return f"{size / (1024 ** 2):.2f} MB"
    else:
        return f"{size / (1024 ** 3):.2f} GB"

def send_reply(chat_id, message_id, text, time_sleep, link_url):

    
    url = f"{api_base_url}{bot_token}/sendMessage"
    params = {
        "chat_id": chat_id,
        "reply_to_message_id": message_id,
        "text": text,
        "parse_mode": "HTML",
        "disable_web_page_preview": "true"
    }
    response = requests.get(url, params=params)
    
    if response.status_code == 200:
        data = response.json()
        reply_message_id = data["result"]["message_id"]  # æå–å›å¤æ¶ˆæ¯çš„ message_id
        logger.info(f"tgå›å¤æ¶ˆæ¯id {message_id} æˆåŠŸï¼")
        
        #åˆ é™¤å›å¤çš„æ¶ˆæ¯
        thread = threading.Thread(target=delete_latest_message, args=(chat_id, reply_message_id, time_sleep))
        thread.start()
    else:
        logger.info(f"tgå›å¤æ¶ˆæ¯id {message_id} å¤±è´¥ï¼")
    
   
   
def delete_latest_message(chat_id, message_id, time_sleep):
    time.sleep(time_sleep)
    url = f"{api_base_url}{bot_token}/deleteMessage"
    params = {
        "chat_id": chat_id,
        "message_id": message_id
    }
    response = requests.get(url, params=params)
    if response.status_code == 200:
        logger.info(f"æˆåŠŸåˆ é™¤æ¶ˆæ¯{message_id}ï¼")
    else:
        logger.info(f"åˆ é™¤æœ€æ–°çš„æ¶ˆæ¯{message_id}ï¼")

def generate_filename(file_name, file_size, caption, file_getpath):
    # ç”Ÿæˆæ–°çš„æ–‡ä»¶å
    file_extension = os.path.splitext(file_name)[1] or os.path.splitext(file_getpath)[1]
    file_size_str = f"({format_size(file_size)})"
    new_file_name = file_name

    if all(char in string.ascii_letters + string.digits + string.punctuation for char in file_name):
        if caption:
            new_file_name = caption[:40]
        else:
            new_file_name = os.path.splitext(file_name)[0]  # å»é™¤åŸå§‹æ–‡ä»¶åçš„åç¼€

    else:
        new_file_name = os.path.splitext(file_name)[0]  # å»é™¤åŸå§‹æ–‡ä»¶åçš„åç¼€


    new_file_name = f"{new_file_name}{file_size_str}{file_extension}"
    return new_file_name    

def download_file(url, file_type, file_name, caption, file_getpath, message_id, chat_id, media_group_id, file_size):
       
    total_size = file_size

    file_name_with_size = generate_filename(file_name, total_size, caption, file_getpath)
    logger.info(f"ã€{media_group_id}ã€‘æ–‡ä»¶{file_name}é‡å‘½åä¸ºï¼š{file_name_with_size}")

    if media_group_id:
        if caption:
            caption_path = caption[:40]
            file_type = f"media_group/{caption_path}ã€{media_group_id}ã€‘"
        else:
            file_type = f"media_group/ã€{media_group_id}ã€‘"

    sub_directory = os.path.join(download_path, file_type)
    create_directory(sub_directory)

    file_path = os.path.join(sub_directory, file_name_with_size)

    os.link(file_getpath, file_path) 
    logger.info(f"ã€{media_group_id}ã€‘{file_getpath},{file_path}")
    
    if enable_upload:
        # æ„é€ è¿œç¨‹è·¯å¾„
        remote_file_path = f"{remote_path}/{file_type}"
            
        # è°ƒç”¨rcloneå‘½ä»¤ä¸Šä¼ æ–‡ä»¶ï¼Œæ­¤å¤„rcloneé€»è¾‘ä¸rclone_upload(local_path, remote_path, second_dir)å‡½æ•°ä¸ç›¸åŒï¼Œä¸å¯ä¿®æ”¹
        # å¼•ç”¨è·¯å¾„ä»¥å¤„ç†ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦
        quoted_file_path = shlex.quote(file_path)
        quoted_remote_file_path = shlex.quote(remote_file_path)

        logger.info(f"rcloneæœ¬åœ°åœ°å€:{quoted_file_path}")
        logger.info(f"rcloneè¿œç¨‹åœ°å€:{quoted_remote_file_path}")
            
        rclone_command = f"rclone move {quoted_file_path} {quoted_remote_file_path} -P"
        result = subprocess.run(rclone_command, shell=True)
        
        time_sleep = 600 # åˆ é™¤å›å¤ä¿¡æ¯æ—¶é—´
        link_url = remote_url + "/" + file_type + "/" + file_name_with_size
        if media_group_id:
            link_url = remote_url + "/" + file_type
            if media_group_id in media_group_id_end_count:
                media_group_id_end_count[media_group_id] += 1
            else:
                media_group_id_end_count[media_group_id] = 1

            media_group_id_start_time = media_group_id_start_count[media_group_id] #æ€»å…±æ¬¡æ•°
            media_group_id_end_time = media_group_id_end_count[media_group_id] #å·²ç»å‡ºç°æ¬¡æ•°
            logging.info(f"ã€{media_group_id}ã€‘æ€»å…± {media_group_id_start_time} å·²ä¸Šä¼ å®Œæˆ{media_group_id_end_time}")
            
            if media_group_id_start_time == media_group_id_end_time:
                logging.info(f"ã€{media_group_id}ã€‘{media_group_id_end_time}ä¸ªæ–‡ä»¶å…¨éƒ¨ä¸Šä¼ å®Œæˆ")
                reply_text = f"ã€{media_group_id}ã€‘{media_group_id_end_time}ä¸ªæ–‡ä»¶å…¨éƒ¨ä¸Šä¼ å®Œæˆ\n\n<a href='{link_url}'>æ–‡ä»¶é“¾æ¥</a>"
                send_reply(chat_id, message_id, reply_text, time_sleep, link_url)   
        else:
            if result.returncode == 0:
                logging.info("ã€{media_group_id}ã€‘æ–‡ä»¶ {file_name_with_size} ä¸Šä¼ å®Œæˆ")
                reply_text = f"ã€{media_group_id}ã€‘æ–‡ä»¶ {file_name_with_size} ä¸Šä¼ å®Œæˆ\n\n<a href='{link_url}'>æ–‡ä»¶é“¾æ¥</a>"
                send_reply(chat_id, message_id, reply_text, time_sleep, link_url)
            else:
                logging.error(f"ã€{media_group_id}ã€‘æ–‡ä»¶ {file_name_with_size} ä¸Šä¼ å¤±è´¥ï¼Œè¿”å›ç ï¼š{result.returncode}")
                reply_text = f"ã€{media_group_id}ã€‘æ–‡ä»¶ {file_name_with_size} ä¸Šä¼ å¤±è´¥ï¼Œè¿”å›ç ï¼š{result.returncode}"
                send_reply(chat_id, message_id, reply_text, time_sleep, link_url)
    else:
        # æœªå¼€å¯rcloneä¸Šä¼ 
        reply_text = f"ä¸€ä¸ªæ–‡ä»¶ {file_name_with_size} ä¸Šä¼ å®Œæˆ\n\n<a href='{link_url}'>æ–‡ä»¶é“¾æ¥</a>"
        send_reply(chat_id, message_id, reply_text, time_sleep, '123123')

def download_media_file(file_id, file_name, file_type, caption, message_id, chat_id, media_group_id):
    get_file_url = f"{api_base_url}{bot_token}/getFile"
    params = {"file_id": file_id}

    retries = 0
    while retries < max_retries:
        try:
            response = requests.get(get_file_url, params=params, timeout=30)  # timeoutå¯è°ƒæ•´
            logger.info(f"ã€{media_group_id} | {file_id}ã€‘\n{' ' * 26}å°è¯•è·å– file_info: {response}")

            file_info = response.json()
            logger.info(f"ã€{media_group_id} | {file_id}ã€‘\n{' ' * 26}file_info: {file_info}")

            if file_info.get("ok") and "result" in file_info:
                file_path = file_info["result"]["file_path"]
                file_size = file_info["result"].get("file_size", 0)
                file_url = f"{api_base_url}{bot_token}/{file_path}"

                download_file(file_url, file_type, file_name, caption, file_path, message_id, chat_id, media_group_id, file_size)
                return  # æˆåŠŸè·å–å¹¶ä¸‹è½½åé€€å‡ºå‡½æ•°
            else:
                logger.warning(f"ã€{media_group_id} | {file_id}ã€‘\n{' ' * 26}è·å–æ–‡ä»¶ä¿¡æ¯å¤±è´¥ï¼Œè¿”å›å€¼: {file_info}")
        except requests.exceptions.RequestException as e:
            logger.warning(f"ã€{media_group_id} | {file_id}ã€‘\n{' ' * 26}serverç«¯telegram-bot-apiè¿˜æœªå°†tgäº‘ç«¯æ–‡ä»¶ä¸‹è½½åˆ°æœ¬åœ°ã€‚\n{' ' * 26}æœ¬æ¬¡è¯·æ±‚å¼‚å¸¸: {e}")

        retries += 1
        logger.info(f"ã€{media_group_id} | {file_id}ã€‘\n{' ' * 26}ç­‰å¾… {retry_delay}s åé‡è¯•ç¬¬ {retries} æ¬¡...")
        time.sleep(retry_delay)

    logger.error(f"ã€{media_group_id} | {file_id}ã€‘\n{' ' * 26}å¤šæ¬¡è¯·æ±‚serverç«¯telegram-bot-apiï¼Œé‡è¯•åä»æœªè·å– file_info: {file_id}ï¼Œä¸å†å°è¯•")

def download_ytdlp_file(url, message_id, chat_id):
    logger.info(f"å¼€å§‹ä¸‹è½½ï¼š{url}")

    ## è·å–ç½‘ç«™ç±»å‹ï¼Œåç»­cookiesæ–‡ä»¶å
    ## ytdlpçš„cookiesæ–‡ä»¶ï¼ŒNetscapeæ ¼å¼
    cmd = f"yt-dlp --print extractor {url}"
    result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
    logger.info(f"result:{result}")
    
    s = str(result)
    m = re.search(r"stdout='(.*?)\\n", s) 

    if m:
        extractor = m.group(1)
        print(extractor)    # BiliBili
    
    logger.info(f"ç½‘ç«™åˆ¤æ–­ï¼š{url} ==> {extractor}")
    cookies = f"./cookies/{extractor}.txt"
    a = create_empty_file(cookies)
    
    logger.info(f"ç½‘ç«™{extractor}å¦‚éœ€ä½¿ç”¨cookiesä¸‹è½½ï¼Œè¯·å°†Netscapeæ ¼å¼cookiesæ·»åŠ åˆ°{cookies}ï¼Œé”™è¯¯cookiesä¼šå¯¼è‡´ä¸‹è½½å¤±è´¥")
    
    # é…ç½® yt-dlp
    file_second = 'ytdlp'
    download_path_tg = os.path.join(download_path, file_second)
    create_directory(download_path_tg)
    logger.info(f"{url}ä¸‹è½½åˆ°ç›®å½•ï¼š{download_path_tg}")

    if a != True:
        ## å­˜åœ¨cookiesæ–‡ä»¶ï¼Œè°ƒç”¨cookies,é”™è¯¯ä¼šå¯¼è‡´ä¸‹è½½å¤±è´¥
        ## --no-playlist \
        cmd = f"""yt-dlp \
        --no-playlist \
        --format 'bv+ba' \
        --output "{download_path_tg}/%(title)s_%(resolution)s_%(id)s.%(ext)s" \
        --retries 10 \
        --fragment-retries 10 \
        --concurrent-fragments 5 \
        --cookies {cookies} \
        --no-overwrites \
        --print after_move:filepath \
        {url}"""
    else:
        ## ä¸å­˜åœ¨cookiesæ–‡ä»¶ï¼Œä¸ä½¿ç”¨cookiesä¸‹è½½
        cmd = f"""yt-dlp \
        --no-playlist \
        --format 'bv+ba' \
        --output "{download_path_tg}/%(title)s_%(resolution)s_%(id)s.%(ext)s" \
        --retries 10 \
        --fragment-retries 10 \
        --concurrent-fragments 5 \
        --no-overwrites \
        --print after_move:filepath \
        {url}"""

        logger.info(f"åˆ é™¤ç©ºç™½æ–‡ä»¶{cookies}")
        os.remove(cookies)

    try:
        # æ•è·è¾“å‡ºï¼Œé¿å…é˜»å¡
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True) #
        if result.returncode == 0:

            downloaded_file = result.stdout.strip().split("\n")[-1]

            if not downloaded_file:
                downloaded_file = download_path_tg
            
            # åç»­æ˜¯å¦ç§»åŠ¨æ–‡ä»¶
            if enable_upload != True:
                logger.info(f"ytdlpä¸‹è½½æˆåŠŸï¼š{url} ==> {download_path_tg}")
                reply_text = f"ytdlpä¸‹è½½æˆåŠŸï¼š{url} ==> {download_path_tg}"
                send_reply(chat_id, message_id, reply_text, time_sleep, '123')
                return

            rclone_upload(downloaded_file, remote_path, file_second, message_id, chat_id)
            
        else:
            logger.error(f"ytdlpä¸‹è½½å¤±è´¥ï¼š{url}")
            reply_text = f"ytdlpä¸‹è½½å¤±è´¥ï¼š{result.stderr}"
            send_reply(chat_id, message_id, reply_text, time_sleep, '123')
    except Exception as e:
        logger.error(f"æ‰§è¡Œå‘½ä»¤å¼‚å¸¸ï¼š{e}")
        reply_text = f"æ‰§è¡Œå‘½ä»¤å¼‚å¸¸ï¼š{e}"
        send_reply(chat_id, message_id, reply_text, time_sleep, '123')


def rclone_upload(local_path, remote_path, second_dir, message_id, chat_id):

    remote_file_path = f"{remote_path}/{second_dir}"
    quoted_file_path = shlex.quote(local_path)
    quoted_remote_file_path = shlex.quote(remote_file_path)
    
    rclone_command = f"rclone move {quoted_file_path} {quoted_remote_file_path} -P"
    result = subprocess.run(rclone_command, shell=True)
    
    if result.returncode == 0:
        logger.info(f"rcloneä¸Šä¼ æˆåŠŸï¼š{quoted_file_path} ==> {quoted_remote_file_path}")
        reply_text = f"rcloneä¸Šä¼ æˆåŠŸï¼š{quoted_file_path} ==> {quoted_remote_file_path}"
        send_reply(chat_id, message_id, reply_text, time_sleep, '123')
        return True
    else:
        logger.error(f"rcloneä¸Šä¼ å¤±è´¥ï¼š{quoted_file_path} ==> {quoted_remote_file_path} | ï¼Œè¿”å›ç ï¼š{result.returncode}")
        reply_text = f"rcloneä¸Šä¼ å¤±è´¥ï¼š{quoted_file_path} ==> {quoted_remote_file_path} | ï¼Œè¿”å›ç ï¼š{result.returncode}"
        send_reply(chat_id, message_id, reply_text, time_sleep, '123')
        return False

def process_message(message, media_group_captions, caption, media_group_id):
    message_id = message['message_id']
    chat_id = message['chat']['id']

    # å°†captionä¼ é€’ç»™åŒä¸€media_group_idçš„å…¶ä»–æ–‡ä»¶
    if media_group_id and media_group_id in media_group_captions:
        caption = media_group_captions[media_group_id]
    
    # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦åœ¨å…è®¸çš„ç”¨æˆ·IDåˆ—è¡¨ä¸­
    if chat_id not in allowed_user_ids:
        logger.info(f"æœªç»æˆæƒçš„ç”¨æˆ·ï¼š{chat_id}")
        return

    if "photo" in message:
        # å¤„ç†ç…§ç‰‡
        photo = message["photo"][-1]  # è·å–æœ€åä¸€å¼ ç…§ç‰‡ï¼ˆåŸå§‹åˆ†è¾¨ç‡ï¼‰
        file_id = photo["file_id"]
        file_name = photo.get("file_name", "photo")
        logger.info(f"ã€{media_group_id} | {file_id}ã€‘\n{' ' * 26}æ”¶åˆ°ç…§ç‰‡æ¶ˆæ¯ï¼Œå¼€å§‹ä¸‹è½½ï¼š{file_name}")
        # download_media_file(file_id, file_name, "photos",caption, message_id, chat_id, media_group_id)
        pool.submit(download_media_file, file_id, file_name, "photos", caption, message_id, chat_id, media_group_id)

    if "document" in message:
        # å¤„ç†æ–‡æ¡£
        document = message["document"]
        file_id = document["file_id"]
        file_name = document.get("file_name", "document")
        logger.info(f"ã€{media_group_id} | {file_id}ã€‘\n{' ' * 26}æ”¶åˆ°æ–‡æ¡£æ¶ˆæ¯ï¼Œå¼€å§‹ä¸‹è½½ï¼š{file_name}")
        # download_media_file(file_id, file_name, "documents",caption, message_id, chat_id, media_group_id)
        pool.submit(download_media_file, file_id, file_name, "documents", caption, message_id, chat_id, media_group_id)

    if "video" in message:
        # å¤„ç†è§†é¢‘
        video = message["video"]
        file_id = video["file_id"]
        file_name = video.get("file_name", "video")
        logger.info(f"ã€{media_group_id} | {file_id}ã€‘\n{' ' * 26}æ”¶åˆ°è§†é¢‘æ¶ˆæ¯ï¼Œå¼€å§‹ä¸‹è½½ï¼š{file_name}")
        #download_media_file(file_id, file_name, "videos",caption, message_id, chat_id, media_group_id)
        #thread = threading.Thread(target=download_media_file, args=(file_id, file_name, "videos", caption, message_id, chat_id, media_group_id))
        #thread.start()
        
        # æäº¤ä»»åŠ¡ç»™çº¿ç¨‹æ± åå°æ‰§è¡Œ
        pool.submit(download_media_file, file_id, file_name, "videos", caption, message_id, chat_id, media_group_id) 

    if "audio" in message:
        # å¤„ç†éŸ³é¢‘
        audio = message["audio"]
        file_id = audio["file_id"]
        file_name = audio.get("file_name", "audio")
        logger.info(f"ã€{media_group_id} | {file_id}ã€‘\n{' ' * 26}æ”¶åˆ°éŸ³é¢‘æ¶ˆæ¯ï¼Œå¼€å§‹ä¸‹è½½ï¼š{file_name}")
        # download_media_file(file_id, file_name, "audios",caption, message_id, chat_id, media_group_id)
        pool.submit(download_media_file, file_id, file_name, "audios", caption, message_id, chat_id, media_group_id)

    if "text" in message:
        # å¤„ç†æ–‡æœ¬æ–‡ä»¶
        text = message["text"]
        #if (text.startswith("/ping") or text.startswith("/start")) and len(text) == 5:
        if (text.startswith("/ping") and len(text) == 5) or (text.startswith("/start") and len(text) == 6) or (text.startswith("/ping@")):
        #if text.startswith("/ping") and len(text) == 5:
            # å¦‚æœæ¶ˆæ¯ä»¥ /ping å¼€å¤´ï¼Œå›å¤ Pong! ğŸ“
            time_sleep = 2
            send_reply(chat_id, message_id, "Pong! ğŸ“", time_sleep, link_url)

            #åˆ é™¤å›å¤çš„æ¶ˆæ¯
            thread = threading.Thread(target=delete_latest_message, args=(chat_id, message_id, time_sleep))
            thread.start()

        ## ä½¿ç”¨yt-dlpä¸‹è½½youtubeç­‰ç½‘ç«™è§†é¢‘ï¼Œè¯·å…ˆå®‰è£…ffmpegä¸ytdlp
        if text.startswith("/ytdlp"):
            if not ytdlp:
                return
            parts = text.split()
            if len(parts) != 2:
                logger.info("è¯·ä½¿ç”¨ï¼š/ytdlp <url>")
                reply_text = "è¯·ä½¿ç”¨ï¼š/ytdlp+ç©ºæ ¼+é“¾æ¥"
                time_sleep = 5
                send_reply(chat_id, message_id, reply_text, time_sleep , '123')

                #åˆ é™¤å›å¤çš„æ¶ˆæ¯
                thread = threading.Thread(target=delete_latest_message, args=(chat_id, message_id, time_sleep))
                thread.start()

                return

            logger.info("æ”¶åˆ°ytdlpå†…å®¹ï¼Œå¼€å§‹ä¸‹è½½...") 
            url = parts[1]
            pool.submit(download_ytdlp_file, url, message_id, chat_id)

def get_updates(offset=None):
    get_updates_url = f"{api_base_url}{bot_token}/getUpdates"
    params = {"offset": offset}

    response = requests.get(get_updates_url, params=params)
    updates = response.json()

    if updates["ok"]:
        return updates["result"]
    else:
        return []

def cleanup_media_group_captions(media_group_captions, media_group_timestamps):
    current_time = time.time()
    # éå†å­—å…¸ä¸­çš„æ‰€æœ‰é¡¹
    for media_group_id, timestamp in list(media_group_timestamps.items()):
        # æ£€æŸ¥æ—¶é—´æˆ³æ˜¯å¦è¶…è¿‡æ¸…ç†é—´éš”
        if current_time - timestamp > cleanup_interval:
            # åˆ é™¤æ—§æ•°æ®
            del media_group_captions[media_group_id]
            del media_group_timestamps[media_group_id]

def get_captions(media_group_id, last_update_id1, media_group_captions, media_group_timestamps):   
    new_updates = get_updates(offset=last_update_id1)
    if new_updates:
        logger.info(f"è°ƒç”¨è¯·æ±‚captionå‡½æ•°ï¼Œlast_update_id1ï¼š[{last_update_id1}]")
        logger.info(f"è°ƒç”¨è¯·æ±‚captionå‡½æ•°ï¼Œupdatesï¼š[{new_updates}]")
        for update in new_updates:
            if "message" in update:
                new_message = update["message"]
                new_media_group_id = new_message.get("media_group_id")
                caption = new_message.get("caption")
                logger.info(f"è°ƒç”¨å‡½æ•°,{last_update_id1} ï¼Œæ–°new_message{new_message}ï¼Œæ–°new_media_group_id{new_media_group_id}ï¼Œæ–°captain{caption}")
                
                if new_media_group_id == media_group_id:
                    if caption:
                        caption = re.sub(r'\n+', ' ', caption) #å¤„ç†é¿å…æ¢è¡Œç¬¦
                        logger.info(f"è°ƒç”¨å‡½æ•°,media_group_id {media_group_id} å­˜åœ¨caption {caption}") 
                        get_media_group_captions(caption, media_group_id, media_group_captions, media_group_timestamps)  
                        return caption
                    else:
                        logger.info(f"è°ƒç”¨å‡½æ•°ï¼Œæœªè·å–åˆ°captain ï¼Œlast_update_id {last_update_id1} ç»§ç»­è·å–caption")
                else:
                    logger.info(f"é€€å‡ºè°ƒç”¨å‡½æ•°ï¼Œåç»­ä¸ºmedia_group_idä¸åŒéƒ¨åˆ†ï¼ŒåŸæ¥{media_group_id} ã€æ–°çš„{new_media_group_id}ï¼ï¼ï¼") 
                    return 

def get_media_group_captions(caption, media_group_id, media_group_captions, media_group_timestamps):
    if caption and media_group_id:
        if media_group_id not in media_group_captions:
            media_group_captions[media_group_id] = caption  # å­˜å‚¨ caption
            media_group_timestamps[media_group_id] = time.time()  # å­˜å‚¨æ—¶é—´æˆ³
            logger.info(f"å­˜å‚¨æœ‰æ•ˆcaptain media_group_idå­—å…¸å¯¹ã€‚captainï¼š[{caption}]ï¼›media_group_idï¼š[{media_group_id}]")
        else:
            # æ›´æ–°æ—¶é—´æˆ³
            media_group_timestamps[media_group_id] = time.time()

        # æ¸…ç†æ—§æ•°æ®
        cleanup_media_group_captions(media_group_captions, media_group_timestamps) 
                             
def main():
    last_update_id = None
    media_group_captions = {}  # media_group_captions å­—å…¸åˆå§‹åŒ–ä¸ºç©º
    
    # å®šä¹‰å­˜å‚¨æ—¶é—´æˆ³çš„å­—å…¸
    media_group_timestamps = {}
    

    while True:
        updates = get_updates(offset=last_update_id)

        if updates:
            #logger.info(f"if updates: {updates}")
            #ä»å•æ¬¡æ›´æ–°çš„æ‰€æœ‰æ¶ˆæ¯ä¸­è·å–caption
            logger.info(f"ä»è·å–çš„æ‰€æœ‰æ¶ˆæ¯ä¸­è·å–caption")
            for update in updates:
                if "message" in update:
                    message = update["message"]
                    caption = message.get("caption")
                    media_group_id = message.get("media_group_id")

                    if caption:
                        caption = re.sub(r'\n+', ' ', caption) #å¤„ç†é¿å…æ¢è¡Œç¬¦

                    get_media_group_captions(caption, media_group_id, media_group_captions, media_group_timestamps)
            logger.info(f"å¼€å§‹forå¾ªç¯ï¼Œé€ä¸€å¤„ç†è·å–çš„æ‰€æœ‰æ¶ˆæ¯...")
            for update in updates:
                #logger.info(f"for update in updatesï¼š{update}")
                if "message" in update:
                    message = update["message"]
                    logger.info(f"å¾ªç¯ä¸­ï¼Œå½“å‰å¤„ç†çš„æ¶ˆæ¯ï¼Œupdate_id:[{last_update_id}]ï¼Œmessage:[{message}]")
                    
                    media_group_id = message.get("media_group_id")
                    caption = message.get("caption")
                    if caption:
                        caption = re.sub(r'\n+', ' ', caption) #å¤„ç†é¿å…æ¢è¡Œç¬¦
                    if media_group_id:
                        if media_group_id in media_group_id_start_count:
                            media_group_id_start_count[media_group_id] += 1
                        else:
                            media_group_id_start_count[media_group_id] = 1

                    # è‹¥media_group_idä¸ä¸ºç©ºï¼Œä»å­—å…¸æŸ¥çœ‹æ˜¯å¦æœ‰caption
                    if media_group_id and media_group_id in media_group_captions:
                        caption = media_group_captions[media_group_id]

                    # ä»å­—å…¸æŸ¥çœ‹æ²¡æœ‰captionï¼Œåˆå­˜åœ¨media_group_idï¼Œé‡æ–°è¯·æ±‚ä¸‹ä¸€è½®tgæ¶ˆæ¯ï¼Œè·å–caption
                    if media_group_id and not caption:
                        last_update_id1 = update["update_id"] + 1
                        #ç”¨ä¸‹ä¸€ä¸ªlast_update_idï¼Œé‡æ–°è¯·æ±‚tgæ¶ˆæ¯
                        caption = get_captions(media_group_id, last_update_id1, media_group_captions, media_group_timestamps)
                        if caption:
                            caption = re.sub(r'\n+', ' ', caption) #å¤„ç†é¿å…æ¢è¡Œç¬¦
                            logger.info(f"è¯·æ±‚ä¸‹ä¸€ä¸ªupdate_id {last_update_id1}ä»¥åçš„æ‰€æœ‰æ¶ˆæ¯ï¼Œå‘ç°media_group_id [{media_group_id}] å­˜åœ¨caption [{caption}]") 
                        else:
                            logger.info(f"è¯·æ±‚ä¸‹ä¸€ä¸ªupdate_id {last_update_id1}ä»¥åçš„æ‰€æœ‰æ¶ˆæ¯ï¼Œå‘ç°media_group_id [{media_group_id}] ä¸å­˜åœ¨caption ï¼ï¼ï¼")                
                    
                    process_message(message, media_group_captions, caption, media_group_id)
                     
                last_update_id = update["update_id"] + 1

if __name__ == "__main__":
    create_directory(download_path)
    main()

